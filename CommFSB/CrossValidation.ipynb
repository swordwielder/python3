{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-0660c14120bc>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-0660c14120bc>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    ds = cosmo_fmri_dataset([data_path '/glm_T_stats_perrun.nii'], ...\u001b[0m\n\u001b[0m                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "config=cosmo_config();\n",
    "data_path=fullfile(config.tutorial_data_path,'ak6','s01');\n",
    "\n",
    "% Load the dataset with VT mask\n",
    "ds = cosmo_fmri_dataset([data_path '/glm_T_stats_perrun.nii'], ...\n",
    "                     'mask', [data_path '/vt_mask.nii']);\n",
    "\n",
    "% remove constant features\n",
    "ds=cosmo_remove_useless_data(ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-9adbec543826>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-9adbec543826>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ds.sa.targets = repmat((1:6)',10,1);\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ds.sa.targets = repmat((1:6)',10,1);\n",
    "ds.sa.chunks = floor(((1:60)-1)/6)'+1;\n",
    "\n",
    "% Add labels as sample attributes\n",
    "classes = {'monkey','lemur','mallard','warbler','ladybug','lunamoth'};\n",
    "ds.sa.labels = repmat(classes,1,10)';\n",
    "\n",
    "% this is good practice after setting attributes manually\n",
    "cosmo_check_dataset(ds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m86\u001b[0m\n\u001b[0;31m    sprintf('%d ',all_pred_alt));\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "nsamples=size(ds.samples,1); % should be 60 for this dataset\n",
    "\n",
    "% allocate space for preditions for all 60 samples\n",
    "all_pred=zeros(nsamples,1);\n",
    "\n",
    "% safety check:\n",
    "% to simplify this exercise, the code below assumes that .sa.chunks is in\n",
    "% the range 1..10; if that is not the case, the code may not work properly.\n",
    "% Therefore an 'assert' statement is used to verify that the chunks are as\n",
    "% required for the remainder of this exercise.\n",
    "assert(isequal(ds.sa.chunks,floor(((1:60)-1)/6)'+1));\n",
    "\n",
    "nfolds=numel(unique(ds.sa.chunks)); % should be 10\n",
    "\n",
    "% run n-fold cross-validation\n",
    "% in the k-th fold (k ranges from 1 to 10), test the LDA classifier on\n",
    "% samples with chunks==k and after training on all other samples.\n",
    "%\n",
    "% (in this exercise this is done manually, but easier solutions involve\n",
    "% using cosmo_nfold_partitioner and cosmo_crossvalidation_measure)\n",
    "for fold=1:nfolds\n",
    "    % make a logical mask (of size 60x1) for the test set. It should have\n",
    "    % the value true where ds.sa.chunks has the same value as 'fold', and\n",
    "    % the value false everywhere else. Assign this to the variable\n",
    "    % 'test_msk'\n",
    "    % >@@>\n",
    "    test_msk=ds.sa.chunks==fold;\n",
    "    % <@@<\n",
    "\n",
    "    % slice the input dataset 'ds' across samples using 'test_msk' so that\n",
    "    % it has only samples in the 'fold'-th chunk. Assign the result to the\n",
    "    % variable 'ds_test';\n",
    "    % >@@>\n",
    "    ds_test=cosmo_slice(ds,test_msk);\n",
    "    % <@@<\n",
    "\n",
    "    % now make another logical mask (of size 60x1) for the training set.\n",
    "    % the value true where ds.sa.chunks has a different value as 'fold',\n",
    "    % and the value false everywhere else. Assign this to the variable\n",
    "    % 'train_msk'\n",
    "    % >@@>\n",
    "    train_msk=ds.sa.chunks~=fold;\n",
    "    % (alternative: train_msk=~test_msk)\n",
    "    % <@@<\n",
    "\n",
    "    % slice the input dataset again using train_msk, and assign to the\n",
    "    % variable 'ds_train'\n",
    "    % >@@>\n",
    "    ds_train=cosmo_slice(ds,train_msk);\n",
    "    % <@@<\n",
    "\n",
    "    % Use cosmo_classify_lda to get predicted targets for the\n",
    "    % samples in 'ds_test'. To do so, use the samples and targets\n",
    "    % from 'ds_train' for training (as first and second argument for\n",
    "    % cosmo_classify_lda), and the samples from 'ds_test' for testing\n",
    "    % (third argument for cosmo_classify_lda).\n",
    "    % Assign the result to the variable 'fold_pred', which should be a 6x1\n",
    "    % vector.\n",
    "    % >@@>\n",
    "    fold_pred=cosmo_classify_lda(ds_train.samples,ds_train.sa.targets,...\n",
    "                                    ds_test.samples);\n",
    "    % <@@<\n",
    "\n",
    "    % store the predictions from 'fold_pred' in the 'all_pred' vector,\n",
    "    % at the positions masked by 'test_msk'.\n",
    "    % >@@>\n",
    "    all_pred(test_msk)=fold_pred;\n",
    "    % <@@<\n",
    "end\n",
    "\n",
    "% safety check:\n",
    "% for this exercise, the following code tests whether the predicted classes\n",
    "% is as they should be (i.e. the correct answer); if not an error is\n",
    "% raised.\n",
    "\n",
    "# expected_pred=[ 1 1 1 2 1 1 2 1 1 1\n",
    "#                 2 1 2 2 2 2 2 2 2 2\n",
    "#                 4 3 1 3 3 4 3 3 3 3\n",
    "#                 4 4 2 4 4 4 4 4 3 2\n",
    "#                 5 5 5 5 5 6 5 5 5 5\n",
    "#                 6 6 6 6 6 6 6 6 6 6];\n",
    "\n",
    "% check that the output is as expected\n",
    "if ~isequal(expected_pred(:),all_pred)\n",
    "    error('expected predictions to be row-vector with [%s]''',...\n",
    "            sprintf('%d ',all_pred_alt));\n",
    "end\n",
    "\n",
    "% Compute classification accuracy of all_pred compared to the targets in\n",
    "% the input dataset 'ds', and assign to a variable 'accuracy'\n",
    "% >@@>\n",
    "accuracy=mean(all_pred==ds.sa.targets);\n",
    "% <@@<\n",
    "\n",
    "% print the accuracy\n",
    "fprintf('\\nLDA all categories n-fold: accuracy %.3f\\n', accuracy);\n",
    "\n",
    "% Visualize confusion matrix\n",
    "% the cosmo_confusion_matrix convenience function is used to compute the\n",
    "% confusion matrix\n",
    "[confusion_matrix,classes]=cosmo_confusion_matrix(ds.sa.targets,all_pred);\n",
    "nclasses=numel(classes);\n",
    "% print confusion matrix to terminal window\n",
    "fprintf('\\nLDA n-fold cross-validation confusion matrix:\\n')\n",
    "disp(confusion_matrix);\n",
    "\n",
    "% make a pretty figure\n",
    "figure\n",
    "imagesc(confusion_matrix,[0 10])\n",
    "title('confusion matrix');\n",
    "set(gca,'XTick',1:nclasses,'XTickLabel',classes);\n",
    "set(gca,'YTick',1:nclasses,'YTickLabel',classes);\n",
    "ylabel('target');\n",
    "xlabel('predicted');\n",
    "colorbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-666d5f2a4956>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-666d5f2a4956>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    nfolds=numel(partitions.train_indices); % should be 10\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "% This exercise replicates the analysis done in Part 1, but now\n",
    "% the the 'cosmo_nfold_partitioner' function is used to create a struct\n",
    "% that defines the cross-validation scheme (it contains the indices\n",
    "% for the train and set samples in each fold)\n",
    "partitions=cosmo_nfold_partitioner(ds);\n",
    "\n",
    "% Show partitions\n",
    "fprintf('\\nPartitions for n-fold cross-validation:\\n');\n",
    "cosmo_disp(partitions)\n",
    "\n",
    "% Count how many folds there are in 'partitions', and assign to the\n",
    "% variable 'nfolds'\n",
    "% >@@>\n",
    "nfolds=numel(partitions.train_indices); % should be 10\n",
    "% <@@<\n",
    "\n",
    "% allocate space for predictions of each sample (pattern) in 'ds'\n",
    "all_pred=zeros(nsamples,1);\n",
    "\n",
    "% As in part 1 (above), perform n-fold cross-validation using the LDA\n",
    "% classifier\n",
    "for fold=1:nfolds\n",
    "    % implement cross-validation and store predicted labels in 'all_pred';\n",
    "    % use the contents of partitions to slice the dataset in train and test\n",
    "    % sets for each fold\n",
    "\n",
    "    % from the 'partitions' struct, get the train indices for the\n",
    "    % 'fold'-th fold and assign to a variable 'train_idxs'\n",
    "    % >@@>\n",
    "    train_idxs=partitions.train_indices{fold};\n",
    "    % <@@<\n",
    "\n",
    "    % do the same for the test indices, and assign to a variable\n",
    "    % 'test_idxs'\n",
    "    % >@@>\n",
    "    test_idxs=partitions.test_indices{fold};\n",
    "    % <@@<\n",
    "\n",
    "    % slice the dataset twice:\n",
    "    % - once using 'train_idxs'; assign the result to 'ds_train'\n",
    "    % - once using 'test_idxs' ; assign the result to 'ds_test'\n",
    "    % >@@>\n",
    "    ds_train=cosmo_slice(ds,train_idxs);\n",
    "    ds_test=cosmo_slice(ds,test_idxs);\n",
    "    % <@@<\n",
    "\n",
    "    % compute predictions for the samples in 'ds_test' after training\n",
    "    % using the samples and targets in 'ds_train'\n",
    "    % >@@>\n",
    "    fold_pred=cosmo_classify_lda(ds_train.samples,ds_train.sa.targets,...\n",
    "                                    ds_test.samples);\n",
    "    % <@@<\n",
    "\n",
    "     % store the predictions from 'fold_pred' in the 'all_pred' vector,\n",
    "    % at the positions indexed by 'test_idxs'.\n",
    "    % >@@>\n",
    "    all_pred(test_idxs)=fold_pred;\n",
    "    % <@@<\n",
    "end\n",
    "\n",
    "% Compute classification accuracy of all_pred compared to the targets in\n",
    "% the input dataset 'ds', and assign to a variable 'accuracy'\n",
    "% >@@>\n",
    "accuracy=mean(all_pred==ds.sa.targets);\n",
    "% <@@<\n",
    "fprintf(['\\nLDA all categories n-fold (with partitioner): '...\n",
    "            'accuracy %.3f\\n'], accuracy);\n",
    "\n",
    "% Note: cosmo_crossvalidation_measure can perform the above operations as\n",
    "% well (and in an easier way), but using that function is not part of\n",
    "% this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
